###  sept 9

- WAIC SE for realiability (from sam)
- reliability (sam)
- go bias performence : 
    -- G vs NG context fit, G seems better but NG w/o go bias seems a bit biased (but someone makes snes)
    -- same for variance ? why?
    -- identifiy line suggests the go bias is better


- accuracy accross cotexts for each aprticiapnts .

- *we prefer variance (over bias) given the ind. diferences aspect

- Param reliability rather than WAIC:
 -- 


TASKS:
(*) debug m5 (i.e eta analysis)


###  aug 19
Init values:
- - Plot the actual difference of init values (m2 better than m3)


R_HAT
- M3: Not very good. Why? One subject? Or a parameter?
- M5: there is something wonky with the betas? Or variance? Is it for specific subjects? Take a look at the behavior of these participants.


beta_go / beta_p
- Within subject vs across subject 
    - Plot within participant 

What is the go bias actually adding??
- Per trial likelihood  (maybe better at the beginning) ?
- 


Go bias analysis
- There is interesting variability (-0.4 /0.6)
- Lots of low beta
- No correlation between beta an go bias.
- inv_logit(0.2) - .5 first trial 5% higher likelihood to make a go action


Model comparison
- Param reliability rather than WAIC


Reliabity of comp- relativity of the core.

Alphas
- m5 is ta_incong actually collapsed to the prior??
- 




TASK:
Compare m4,5,6 w and w/o go bias (identity diagonals)

Model 4,5,6 w/o go_bias


- How would you calc predictive_acc
    -  Split go /no go (flip for no go)


(1) R_hats for all models (=!1) explore why poor fitting
(2) identity plots - compare w and w/o go bias
(3) m5 incong eta
(4) reliability 